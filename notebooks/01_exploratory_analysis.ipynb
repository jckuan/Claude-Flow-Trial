{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis - Rossmann Store Sales\n",
    "\n",
    "**Agent**: DataExplorer\n",
    "**Date**: 2025-11-06\n",
    "**Objective**: Comprehensive analysis of training data to understand patterns, data quality, and inform feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Initial Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data\n",
    "train = pd.read_csv('../data/rossmann-store-sales/train.csv', parse_dates=['Date'])\n",
    "\n",
    "print(f\"Dataset Shape: {train.shape}\")\n",
    "print(f\"Number of Stores: {train['Store'].nunique()}\")\n",
    "print(f\"Date Range: {train['Date'].min()} to {train['Date'].max()}\")\n",
    "print(f\"Total Days: {(train['Date'].max() - train['Date'].min()).days}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types and structure\n",
    "print(\"Data Types:\")\n",
    "print(train.dtypes)\n",
    "print(\"\\nData Info:\")\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Missing Values Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing = train.isnull().sum()\n",
    "missing_pct = (missing / len(train)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing_Count': missing,\n",
    "    'Percentage': missing_pct\n",
    "}).sort_values('Missing_Count', ascending=False)\n",
    "\n",
    "print(\"Missing Values Summary:\")\n",
    "print(missing_df[missing_df['Missing_Count'] > 0])\n",
    "\n",
    "if missing_df['Missing_Count'].sum() == 0:\n",
    "    print(\"\\n✓ No missing values found in the dataset!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical features statistics\n",
    "print(\"Numerical Features Statistics:\")\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features\n",
    "categorical_cols = ['DayOfWeek', 'Open', 'Promo', 'StateHoliday', 'SchoolHoliday']\n",
    "print(\"Categorical Features Summary:\")\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(train[col].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Target Variable Analysis (Sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sales distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Histogram\n",
    "axes[0, 0].hist(train['Sales'], bins=100, edgecolor='black', alpha=0.7)\n",
    "axes[0, 0].set_title('Sales Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Sales')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].axvline(train['Sales'].mean(), color='red', linestyle='--', label=f'Mean: {train[\"Sales\"].mean():.2f}')\n",
    "axes[0, 0].axvline(train['Sales'].median(), color='green', linestyle='--', label=f'Median: {train[\"Sales\"].median():.2f}')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Box plot\n",
    "axes[0, 1].boxplot(train['Sales'])\n",
    "axes[0, 1].set_title('Sales Box Plot', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_ylabel('Sales')\n",
    "\n",
    "# Log-transformed histogram\n",
    "sales_nonzero = train[train['Sales'] > 0]['Sales']\n",
    "axes[1, 0].hist(np.log1p(sales_nonzero), bins=100, edgecolor='black', alpha=0.7, color='orange')\n",
    "axes[1, 0].set_title('Log-Transformed Sales Distribution (Sales > 0)', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Log(Sales + 1)')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Q-Q plot\n",
    "from scipy import stats\n",
    "stats.probplot(sales_nonzero, dist=\"norm\", plot=axes[1, 1])\n",
    "axes[1, 1].set_title('Q-Q Plot (Sales > 0)', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../docs/sales_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Sales Statistics:\")\n",
    "print(f\"  Mean: {train['Sales'].mean():.2f}\")\n",
    "print(f\"  Median: {train['Sales'].median():.2f}\")\n",
    "print(f\"  Std Dev: {train['Sales'].std():.2f}\")\n",
    "print(f\"  Min: {train['Sales'].min():.2f}\")\n",
    "print(f\"  Max: {train['Sales'].max():.2f}\")\n",
    "print(f\"  Skewness: {train['Sales'].skew():.2f}\")\n",
    "print(f\"  Kurtosis: {train['Sales'].kurtosis():.2f}\")\n",
    "print(f\"\\nZero Sales Records: {(train['Sales'] == 0).sum()} ({(train['Sales'] == 0).sum() / len(train) * 100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Store-Level Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sales by store\n",
    "store_stats = train.groupby('Store').agg({\n",
    "    'Sales': ['mean', 'median', 'std', 'min', 'max', 'count'],\n",
    "    'Customers': ['mean', 'median']\n",
    "}).round(2)\n",
    "\n",
    "print(\"Store-Level Statistics (Top 10 by Average Sales):\")\n",
    "print(store_stats.sort_values(('Sales', 'mean'), ascending=False).head(10))\n",
    "\n",
    "# Visualize store performance\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "store_avg_sales = train.groupby('Store')['Sales'].mean().sort_values(ascending=False)\n",
    "axes[0].bar(range(len(store_avg_sales)), store_avg_sales.values, alpha=0.7)\n",
    "axes[0].set_title('Average Sales by Store (Sorted)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Store Rank')\n",
    "axes[0].set_ylabel('Average Sales')\n",
    "axes[0].axhline(store_avg_sales.mean(), color='red', linestyle='--', label='Overall Mean')\n",
    "axes[0].legend()\n",
    "\n",
    "# Sales variance by store\n",
    "store_std = train.groupby('Store')['Sales'].std().sort_values(ascending=False)\n",
    "axes[1].bar(range(len(store_std)), store_std.values, alpha=0.7, color='orange')\n",
    "axes[1].set_title('Sales Standard Deviation by Store (Sorted)', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Store Rank')\n",
    "axes[1].set_ylabel('Sales Std Dev')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../docs/store_performance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Temporal Patterns Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temporal features\n",
    "train['Year'] = train['Date'].dt.year\n",
    "train['Month'] = train['Date'].dt.month\n",
    "train['Day'] = train['Date'].dt.day\n",
    "train['WeekOfYear'] = train['Date'].dt.isocalendar().week\n",
    "train['Quarter'] = train['Date'].dt.quarter\n",
    "\n",
    "# Sales over time\n",
    "fig, axes = plt.subplots(3, 2, figsize=(16, 14))\n",
    "\n",
    "# Daily sales trend\n",
    "daily_sales = train.groupby('Date')['Sales'].mean().reset_index()\n",
    "axes[0, 0].plot(daily_sales['Date'], daily_sales['Sales'], alpha=0.6)\n",
    "axes[0, 0].set_title('Average Daily Sales Over Time', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Date')\n",
    "axes[0, 0].set_ylabel('Average Sales')\n",
    "axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Sales by day of week\n",
    "dow_sales = train.groupby('DayOfWeek')['Sales'].mean()\n",
    "axes[0, 1].bar(dow_sales.index, dow_sales.values, color='skyblue', alpha=0.7)\n",
    "axes[0, 1].set_title('Average Sales by Day of Week', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Day of Week (1=Mon, 7=Sun)')\n",
    "axes[0, 1].set_ylabel('Average Sales')\n",
    "axes[0, 1].set_xticks(range(1, 8))\n",
    "\n",
    "# Sales by month\n",
    "monthly_sales = train.groupby('Month')['Sales'].mean()\n",
    "axes[1, 0].bar(monthly_sales.index, monthly_sales.values, color='lightgreen', alpha=0.7)\n",
    "axes[1, 0].set_title('Average Sales by Month', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Month')\n",
    "axes[1, 0].set_ylabel('Average Sales')\n",
    "axes[1, 0].set_xticks(range(1, 13))\n",
    "\n",
    "# Sales by year\n",
    "yearly_sales = train.groupby('Year')['Sales'].mean()\n",
    "axes[1, 1].bar(yearly_sales.index, yearly_sales.values, color='coral', alpha=0.7)\n",
    "axes[1, 1].set_title('Average Sales by Year', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Year')\n",
    "axes[1, 1].set_ylabel('Average Sales')\n",
    "\n",
    "# Weekly trend\n",
    "weekly_sales = train.groupby('WeekOfYear')['Sales'].mean()\n",
    "axes[2, 0].plot(weekly_sales.index, weekly_sales.values, marker='o', markersize=3, alpha=0.6)\n",
    "axes[2, 0].set_title('Average Sales by Week of Year', fontsize=14, fontweight='bold')\n",
    "axes[2, 0].set_xlabel('Week of Year')\n",
    "axes[2, 0].set_ylabel('Average Sales')\n",
    "axes[2, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Quarterly pattern\n",
    "quarterly_sales = train.groupby('Quarter')['Sales'].mean()\n",
    "axes[2, 1].bar(quarterly_sales.index, quarterly_sales.values, color='purple', alpha=0.7)\n",
    "axes[2, 1].set_title('Average Sales by Quarter', fontsize=14, fontweight='bold')\n",
    "axes[2, 1].set_xlabel('Quarter')\n",
    "axes[2, 1].set_ylabel('Average Sales')\n",
    "axes[2, 1].set_xticks(range(1, 5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../docs/temporal_patterns.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Relationships and Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "numerical_features = ['Store', 'DayOfWeek', 'Sales', 'Customers', 'Open', 'Promo', 'SchoolHoliday']\n",
    "corr_matrix = train[numerical_features].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=1, fmt='.3f', vmin=-1, vmax=1)\n",
    "plt.title('Feature Correlation Matrix', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('../docs/correlation_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Strongest correlations with Sales:\")\n",
    "print(corr_matrix['Sales'].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Promotional and Holiday Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Promo effect\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Promo vs No Promo\n",
    "promo_sales = train.groupby('Promo')['Sales'].mean()\n",
    "axes[0, 0].bar(['No Promo', 'Promo'], promo_sales.values, color=['lightcoral', 'lightgreen'], alpha=0.7)\n",
    "axes[0, 0].set_title('Average Sales: Promo vs No Promo', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_ylabel('Average Sales')\n",
    "for i, v in enumerate(promo_sales.values):\n",
    "    axes[0, 0].text(i, v + 100, f'{v:.0f}', ha='center', fontweight='bold')\n",
    "\n",
    "# School Holiday effect\n",
    "school_holiday_sales = train.groupby('SchoolHoliday')['Sales'].mean()\n",
    "axes[0, 1].bar(['No Holiday', 'School Holiday'], school_holiday_sales.values, \n",
    "               color=['lightblue', 'lightyellow'], alpha=0.7)\n",
    "axes[0, 1].set_title('Average Sales: School Holiday Effect', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_ylabel('Average Sales')\n",
    "for i, v in enumerate(school_holiday_sales.values):\n",
    "    axes[0, 1].text(i, v + 100, f'{v:.0f}', ha='center', fontweight='bold')\n",
    "\n",
    "# State Holiday effect\n",
    "state_holiday_sales = train.groupby('StateHoliday')['Sales'].mean().sort_values(ascending=False)\n",
    "axes[1, 0].bar(range(len(state_holiday_sales)), state_holiday_sales.values, alpha=0.7)\n",
    "axes[1, 0].set_title('Average Sales by State Holiday Type', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('State Holiday (0=None, a=Public, b=Easter, c=Christmas)')\n",
    "axes[1, 0].set_ylabel('Average Sales')\n",
    "axes[1, 0].set_xticks(range(len(state_holiday_sales)))\n",
    "axes[1, 0].set_xticklabels(state_holiday_sales.index)\n",
    "\n",
    "# Open vs Closed\n",
    "open_sales = train.groupby('Open')['Sales'].mean()\n",
    "axes[1, 1].bar(['Closed', 'Open'], open_sales.values, color=['red', 'green'], alpha=0.7)\n",
    "axes[1, 1].set_title('Average Sales: Open vs Closed', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_ylabel('Average Sales')\n",
    "for i, v in enumerate(open_sales.values):\n",
    "    axes[1, 1].text(i, v + 100, f'{v:.0f}', ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../docs/promotional_effects.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPromo Effect Analysis:\")\n",
    "print(f\"  Average Sales (No Promo): {promo_sales[0]:.2f}\")\n",
    "print(f\"  Average Sales (Promo): {promo_sales[1]:.2f}\")\n",
    "print(f\"  Promo Lift: {((promo_sales[1] / promo_sales[0] - 1) * 100):.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Customer Behavior Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sales per customer\n",
    "train['SalesPerCustomer'] = train['Sales'] / train['Customers']\n",
    "train['SalesPerCustomer'] = train['SalesPerCustomer'].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Sales vs Customers scatter\n",
    "sample = train[train['Open'] == 1].sample(min(5000, len(train)))\n",
    "axes[0, 0].scatter(sample['Customers'], sample['Sales'], alpha=0.3, s=10)\n",
    "axes[0, 0].set_title('Sales vs Number of Customers', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Customers')\n",
    "axes[0, 0].set_ylabel('Sales')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Sales per customer distribution\n",
    "spc_data = train[(train['Open'] == 1) & (train['SalesPerCustomer'].notna())]['SalesPerCustomer']\n",
    "axes[0, 1].hist(spc_data, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0, 1].set_title('Sales Per Customer Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Sales Per Customer')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].axvline(spc_data.mean(), color='red', linestyle='--', label=f'Mean: {spc_data.mean():.2f}')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Customers by day of week\n",
    "dow_customers = train[train['Open'] == 1].groupby('DayOfWeek')['Customers'].mean()\n",
    "axes[1, 0].bar(dow_customers.index, dow_customers.values, color='teal', alpha=0.7)\n",
    "axes[1, 0].set_title('Average Customers by Day of Week', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Day of Week (1=Mon, 7=Sun)')\n",
    "axes[1, 0].set_ylabel('Average Customers')\n",
    "axes[1, 0].set_xticks(range(1, 8))\n",
    "\n",
    "# Sales per customer by promo\n",
    "spc_promo = train[(train['Open'] == 1) & (train['SalesPerCustomer'].notna())].groupby('Promo')['SalesPerCustomer'].mean()\n",
    "axes[1, 1].bar(['No Promo', 'Promo'], spc_promo.values, color=['orange', 'green'], alpha=0.7)\n",
    "axes[1, 1].set_title('Sales Per Customer: Promo Effect', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_ylabel('Sales Per Customer')\n",
    "for i, v in enumerate(spc_promo.values):\n",
    "    axes[1, 1].text(i, v + 0.5, f'{v:.2f}', ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../docs/customer_behavior.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nCustomer Behavior Insights:\")\n",
    "print(f\"  Average Sales Per Customer: ${spc_data.mean():.2f}\")\n",
    "print(f\"  Median Sales Per Customer: ${spc_data.median():.2f}\")\n",
    "print(f\"  Correlation (Sales, Customers): {train['Sales'].corr(train['Customers']):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify outliers using IQR method\n",
    "def detect_outliers_iqr(data, column, multiplier=1.5):\n",
    "    Q1 = data[column].quantile(0.25)\n",
    "    Q3 = data[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - multiplier * IQR\n",
    "    upper_bound = Q3 + multiplier * IQR\n",
    "    outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
    "    return outliers, lower_bound, upper_bound\n",
    "\n",
    "# Sales outliers (only for open stores)\n",
    "open_stores = train[train['Open'] == 1]\n",
    "sales_outliers, sales_lower, sales_upper = detect_outliers_iqr(open_stores, 'Sales')\n",
    "\n",
    "print(f\"Sales Outliers (Open Stores):\")\n",
    "print(f\"  Lower Bound: {sales_lower:.2f}\")\n",
    "print(f\"  Upper Bound: {sales_upper:.2f}\")\n",
    "print(f\"  Number of Outliers: {len(sales_outliers)} ({len(sales_outliers)/len(open_stores)*100:.2f}%)\")\n",
    "\n",
    "# Customer outliers\n",
    "customer_outliers, cust_lower, cust_upper = detect_outliers_iqr(open_stores, 'Customers')\n",
    "print(f\"\\nCustomer Outliers (Open Stores):\")\n",
    "print(f\"  Lower Bound: {cust_lower:.2f}\")\n",
    "print(f\"  Upper Bound: {cust_upper:.2f}\")\n",
    "print(f\"  Number of Outliers: {len(customer_outliers)} ({len(customer_outliers)/len(open_stores)*100:.2f}%)\")\n",
    "\n",
    "# Visualize outliers\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "axes[0].boxplot(open_stores['Sales'])\n",
    "axes[0].set_title('Sales Box Plot (Open Stores)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Sales')\n",
    "axes[0].axhline(sales_upper, color='red', linestyle='--', label='Upper Bound')\n",
    "axes[0].axhline(sales_lower, color='red', linestyle='--', label='Lower Bound')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].boxplot(open_stores['Customers'])\n",
    "axes[1].set_title('Customers Box Plot (Open Stores)', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Customers')\n",
    "axes[1].axhline(cust_upper, color='red', linestyle='--', label='Upper Bound')\n",
    "axes[1].axhline(cust_lower, color='red', linestyle='--', label='Lower Bound')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../docs/outliers_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Data Quality Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data quality report\n",
    "quality_report = {\n",
    "    'Total Records': len(train),\n",
    "    'Unique Stores': train['Store'].nunique(),\n",
    "    'Date Range': f\"{train['Date'].min().date()} to {train['Date'].max().date()}\",\n",
    "    'Missing Values': train.isnull().sum().sum(),\n",
    "    'Duplicate Rows': train.duplicated().sum(),\n",
    "    'Zero Sales Records': (train['Sales'] == 0).sum(),\n",
    "    'Closed Store Records': (train['Open'] == 0).sum(),\n",
    "    'Records with Promo': (train['Promo'] == 1).sum(),\n",
    "    'School Holiday Records': (train['SchoolHoliday'] == 1).sum(),\n",
    "    'State Holiday Records': (train['StateHoliday'] != '0').sum()\n",
    "}\n",
    "\n",
    "print(\"\\n=\" * 60)\n",
    "print(\"DATA QUALITY SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "for key, value in quality_report.items():\n",
    "    print(f\"{key:.<40} {value}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Key Findings and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "findings = f\"\"\"\n",
    "KEY FINDINGS FROM EXPLORATORY DATA ANALYSIS:\n",
    "\n",
    "1. DATA QUALITY:\n",
    "   - No missing values in the dataset\n",
    "   - {len(train):,} total records covering {train['Store'].nunique()} stores\n",
    "   - Date range: {train['Date'].min().date()} to {train['Date'].max().date()}\n",
    "   - {(train['Sales'] == 0).sum():,} records with zero sales ({(train['Sales'] == 0).sum()/len(train)*100:.1f}%)\n",
    "\n",
    "2. TARGET VARIABLE (Sales):\n",
    "   - Mean: ${train['Sales'].mean():.2f}\n",
    "   - Median: ${train['Sales'].median():.2f}\n",
    "   - Highly right-skewed distribution (skewness: {train['Sales'].skew():.2f})\n",
    "   - Log transformation recommended for modeling\n",
    "   - Strong correlation with number of customers (r={train['Sales'].corr(train['Customers']):.3f})\n",
    "\n",
    "3. TEMPORAL PATTERNS:\n",
    "   - Clear weekly seasonality (higher sales mid-week)\n",
    "   - Monthly patterns show peak sales in December\n",
    "   - Day 7 (Sunday) shows reduced sales activity\n",
    "   - Yearly trends indicate stable or growing sales\n",
    "\n",
    "4. PROMOTIONAL EFFECTS:\n",
    "   - Promo increases average sales by {((promo_sales[1]/promo_sales[0]-1)*100):.1f}%\n",
    "   - {(train['Promo']==1).sum()/len(train)*100:.1f}% of records have active promotions\n",
    "   - Promo also affects sales per customer metric\n",
    "\n",
    "5. STORE HETEROGENEITY:\n",
    "   - Significant variation in sales performance across stores\n",
    "   - Top stores have >3x sales of bottom stores\n",
    "   - Store-specific features will be crucial for modeling\n",
    "\n",
    "6. CUSTOMER BEHAVIOR:\n",
    "   - Average sales per customer: ${spc_data.mean():.2f}\n",
    "   - Near-linear relationship between customers and sales\n",
    "   - Customer count is highly predictive of sales\n",
    "\n",
    "RECOMMENDATIONS FOR FEATURE ENGINEERING:\n",
    "\n",
    "1. Temporal Features:\n",
    "   - Day of week indicators\n",
    "   - Month, quarter indicators\n",
    "   - Weekend/weekday flags\n",
    "   - Days to/from holidays\n",
    "   - Week of year for seasonal patterns\n",
    "\n",
    "2. Lag Features:\n",
    "   - Previous day/week sales\n",
    "   - Rolling averages (7-day, 30-day)\n",
    "   - Year-over-year comparisons\n",
    "\n",
    "3. Store Features:\n",
    "   - Store average sales\n",
    "   - Store sales volatility\n",
    "   - Store-specific promo effects\n",
    "\n",
    "4. Interaction Features:\n",
    "   - Promo × Day of week\n",
    "   - School holiday × Day of week\n",
    "   - Store × Promo interactions\n",
    "\n",
    "5. Target Encoding:\n",
    "   - Store-level statistics\n",
    "   - Time-period aggregations\n",
    "\n",
    "6. Data Preprocessing:\n",
    "   - Handle zero sales separately (closed stores)\n",
    "   - Consider log transformation of target\n",
    "   - Outlier treatment strategy needed\n",
    "   - Train/validation split by time (time-series nature)\n",
    "\"\"\"\n",
    "\n",
    "print(findings)\n",
    "\n",
    "# Save findings to file\n",
    "with open('../docs/eda_key_findings.txt', 'w') as f:\n",
    "    f.write(findings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This exploratory analysis has revealed:\n",
    "- Clean dataset with no missing values\n",
    "- Strong temporal patterns requiring time-based features\n",
    "- Significant promotional effects on sales\n",
    "- High store-level heterogeneity\n",
    "- Clear relationship between customers and sales\n",
    "- Need for log transformation of target variable\n",
    "\n",
    "Next steps:\n",
    "1. Feature engineering based on identified patterns\n",
    "2. Additional store-level data integration\n",
    "3. Time-series cross-validation strategy\n",
    "4. Model selection and baseline establishment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
